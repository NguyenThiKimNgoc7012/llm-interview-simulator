import os
from stat import FILE_ATTRIBUTE_COMPRESSED
from groq import Groq
from PyPDF2 import PdfReader
from docx import Document
import re
import os
from PyPDF2 import PdfReader
from docx import Document
import langchain_ollama
from llm import ask_llama
from rag_pipeline import retrieve_relevant_chunks 
from utils import extract_text_from_cv
from embedding import create_faiss_index, add_embeddings_to_faiss
import faiss
from langchain_ollama import OllamaEmbeddings
from langchain.chains import RetrievalQA
import json
import numpy as np
from flask import session
from langdetect import detect



client = Groq(api_key=os.getenv("GROQ_API_KEY"))



def ask_question(user_info, history, difficulty=0):
    job_title = user_info["job_title"]
    level = user_info["level"]
    language = user_info.get("language", "vi")
    job_description = user_info.get("job_description", "")

    dialogue = "\n".join([
        f"{'HR' if msg['role'] == 'bot' else ('·ª®ng vi√™n' if language == 'vi' else 'Candidate')}: {msg['text']}"
        for msg in history[-6:]
    ])

    difficulty_note = (
        "C√¢u h·ªèi n√™n ƒë∆°n gi·∫£n, ƒë·ªÉ hi·ªÉu ƒë∆∞·ª£c ki·∫øn th·ª©c c∆° b·∫£n." if difficulty < 3 else
        "C√¢u h·ªèi n√™n ·ªü m·ª©c trung b√¨nh, ki·ªÉm tra ki·∫øn th·ª©c v√† k·ªπ nƒÉng th·ª±c t·∫ø." if difficulty < 6 else
        "C√¢u h·ªèi n√™n n√¢ng cao, ƒë√°nh gi√° kh·∫£ nƒÉng gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ chuy√™n s√¢u."
    )

    if language == "vi":
        prompt = f"""
        B·∫°n l√† chuy√™n gia tuy·ªÉn d·ª•ng. Vai tr√≤ c·ªßa b·∫°n l√† ƒë·∫∑t c√¢u h·ªèi PH·ªéNG V·∫§N B·∫∞NG TI·∫æNG VI·ªÜT cho ·ª©ng vi√™n v·ªã tr√≠ {job_title}, c·∫•p ƒë·ªô {level}.
        M√¥ t·∫£ c√¥ng vi·ªác: {job_description}
        {difficulty_note}
        ƒêo·∫°n h·ªôi tho·∫°i g·∫ßn ƒë√¢y:
        {dialogue}
        H√£y ƒë·∫∑t 1 c√¢u h·ªèi ph·ªèng v·∫•n ti·∫øp theo duy nh·∫•t. Vi·∫øt b·∫±ng TI·∫æNG VI·ªÜT, kh√¥ng gi·ªõi thi·ªáu, kh√¥ng ƒë√°nh s·ªë.
        """
    else:
        prompt = f"""
        You are an HR expert. Your role is to ask INTERVIEW QUESTIONS IN ENGLISH for the position {job_title}, level {level}.
        Job description: {job_description}
        {difficulty_note}
        Dialogue history:
        {dialogue}
        Ask one next interview question only. Be concise, in ENGLISH. No intro, no numbering.
        """

    completion = client.chat.completions.create(
        model="llama3-8b-8192",
        messages=[
            {"role": "system", "content": "You are an expert HR interviewer."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.7
    )

    return completion.choices[0].message.content.strip()



def get_suggested_answer(question, user_answer, language, user_info):
    job_title = user_info.get("job_title") 
    level = user_info.get("level")  
    job_description = user_info.get("job_description")  

   
    if not job_title or not level or not job_description:
        raise ValueError("Thi·∫øu th√¥ng tin quan tr·ªçng trong user_info")

    
    if language == "vi":
        prompt = f"""
        C√¢u h·ªèi: {question}
        C√¢u tr·∫£ l·ªùi c·ªßa ·ª©ng vi√™n: {user_answer}
        G·ª£i √Ω m·ªôt c√¢u tr·∫£ l·ªùi t·ªët h∆°n, chi ti·∫øt v√† c·ª• th·ªÉ h∆°n cho c√¢u h·ªèi tr√™n.B·∫Øt bu·ªôc sinh c√¢u tr·∫£ l·ªùi t·ªët h∆°n b·∫±ng ti·∫øng vi·ªát.Tuy·ªát ƒë·ªëi kh√¥ng c√≥ ti·∫øng anh v√†o. 
        C√¢u tr·∫£ l·ªùi g·ª£i √Ω n√™n th·ªÉ hi·ªán ki·∫øn th·ª©c v√† k·ªπ nƒÉng c·ªßa ·ª©ng vi√™n m·ªôt c√°ch r√µ r√†ng v√† thuy·∫øt ph·ª•c.
        """
    else:  
        prompt = f"""
        Question: {question}
        Candidate's answer: {user_answer}
        Suggest a better, more detailed and specific answer to the question above.
        The suggested answer should clearly demonstrate the candidate's knowledge and skills in a convincing way.
        """


    logic_response = client.chat.completions.create(
        model="llama3-8b-8192",  
        messages=[
            {"role": "system", "content": "You are an expert at suggesting better interview answers."},
            {"role": "user", "content": prompt.strip()}
        ],
        temperature=0.7  
    )

   
    print(logic_response)

    
    try:
        return logic_response.choices[0].message.content.strip() 
    except AttributeError:
        return "Kh√¥ng c√≥ c√¢u tr·∫£ l·ªùi g·ª£i √Ω."  



def follow_up(answer, context):
    language = context.get("language", "vi")
    last_question = context.get("last_question", "")
    job_title = context.get("job_title", "")
    job_description = context.get("job_description", "")

    # B∆∞·ªõc 1: Ki·ªÉm tra ƒë·ªô kh·ªõp gi·ªØa c√¢u h·ªèi v√† c√¢u tr·∫£ l·ªùi
    logic_prompt = f"""
    D∆∞·ªõi ƒë√¢y l√† m·ªôt c·∫∑p c√¢u h·ªèi v√† c√¢u tr·∫£ l·ªùi trong bu·ªïi ph·ªèng v·∫•n:

    - C√¢u h·ªèi: "{last_question}"
    - Tr·∫£ l·ªùi: "{answer}"

    Theo b·∫°n, c√¢u tr·∫£ l·ªùi n√†y c√≥ ƒë√∫ng tr·ªçng t√¢m v√† ƒë·∫ßy ƒë·ªß ƒë·ªÉ ph·∫£n h·ªìi cho c√¢u h·ªèi kh√¥ng?

    Tr·∫£ l·ªùi DUY NH·∫§T 1 T·ª™:
    - "C√ì" n·∫øu ƒë√∫ng v√† r√µ r√†ng
    - "KH√îNG" n·∫øu kh√¥ng tr·∫£ l·ªùi ƒë√∫ng tr·ªçng t√¢m ho·∫∑c c√≤n m∆° h·ªì
    """

    logic_response = client.chat.completions.create(
        model="llama3-8b-8192",
        messages=[
            {"role": "system", "content": "B·∫°n l√† chuy√™n gia ƒë√°nh gi√° ƒë·ªô ph√π h·ª£p gi·ªØa c√¢u h·ªèi v√† c√¢u tr·∫£ l·ªùi."},
            {"role": "user", "content": logic_prompt.strip()}
        ],
        temperature=0
    )

    logic_decision = logic_response.choices[0].message.content.strip().lower()

    
    if logic_decision == "c√≥" and len(answer.strip().split()) >= 10:
        return None

    #  Sinh c√¢u h·ªèi follow-up 
    if language == "vi":
        prompt = f"""
        B·∫°n l√† chuy√™n gia tuy·ªÉn d·ª•ng cho v·ªã tr√≠ {job_title}.
        ·ª®ng vi√™n v·ª´a tr·∫£ l·ªùi ch∆∞a r√µ cho c√¢u h·ªèi: "{last_question}"
        C√¢u tr·∫£ l·ªùi l√†: "{answer}"

        M√¥ t·∫£ c√¥ng vi·ªác: {job_description}

        H√£y vi·∫øt m·ªôt c√¢u h·ªèi follow-up duy nh·∫•t b·∫±ng ti·∫øng Vi·ªát ƒë·ªÉ khai th√°c s√¢u h∆°n k·ªπ nƒÉng, kinh nghi·ªám ho·∫∑c t∆∞ duy c·ªßa ·ª©ng vi√™n.
        - KH√îNG m·ªü ƒë·∫ßu, KH√îNG ƒë√°nh s·ªë, KH√îNG xin ph√©p
        - ∆Øu ti√™n s√°t n·ªôi dung c√¥ng vi·ªác
        """
    else:
        prompt = f"""
        You are a recruiter hiring for the position of {job_title}.
        The candidate gave a vague answer to the question: "{last_question}"
        Their answer was: "{answer}"

        Job description: {job_description}

        Write ONE follow-up question in English to go deeper into the candidate‚Äôs skill, experience, or mindset.
        - Do NOT include introduction or numbering.
        - Be relevant and specific.
        """

    followup_response = client.chat.completions.create(
        model="llama3-8b-8192",
        messages=[
            {"role": "system", "content": "B·∫°n l√† chuy√™n gia ph·ªèng v·∫•n gi√†u kinh nghi·ªám."},
            {"role": "user", "content": prompt.strip()}
        ],
        temperature=0.7
    )

    return followup_response.choices[0].message.content.strip()

def get_feedback_on_answer(question, answer, language="vi"):
    prompt_vi = f"""
    B·∫°n l√† chuy√™n gia tuy·ªÉn d·ª•ng.
    C√¢u h·ªèi: {question}
    Tr·∫£ l·ªùi c·ªßa ·ª©ng vi√™n: {answer}

    H√£y nh·∫≠n x√©t ng·∫Øn g·ªçn (1 c√¢u), mang t√≠nh ph·∫£n h·ªìi chuy√™n m√¥n: r√µ r√†ng kh√¥ng, ƒë√∫ng ch∆∞a, c·∫ßn h·ªèi th√™m kh√¥ng.B·∫Øt bu·ªôc sinh c√¢u tr·∫£ l·ªùi t·ªët h∆°n b·∫±ng ti·∫øng vi·ªát.Tuy·ªát ƒë·ªëi kh√¥ng c√≥ ti·∫øng anh v√†o.
    Ch·ªâ khi ·ª©ng vi√™n th·∫≠t s·ª± kh√¥ng ph√π h·ª£p, h√£y b·∫Øt ƒë·∫ßu ph·∫£n h·ªìi b·∫±ng: "KH√îNG PH√ô H·ª¢P:".
    """


    prompt_en = f"""
    You are an HR expert evaluating a candidate's response during an interview.
    Question: {question}
    Candidate's answer: {answer}

    Please give a short (1-sentence) feedback in English.

    - If the candidate is clearly UNSUITABLE for the position, your answer MUST start with "UNSUITABLE:" and explain briefly why.
    - If the candidate gives a suitable or acceptable answer, start with "CLEAR:" and provide a brief evaluation.

    Be concise and professional. Only return the feedback sentence.
    """


    prompt = prompt_vi if language == "vi" else prompt_en

    completion = client.chat.completions.create(
        model="llama3-8b-8192",
        messages=[
            {"role": "system", "content": "You are a professional interviewer."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.7
    )
    return completion.choices[0].message.content.strip()


def should_terminate_early(messages, user_info):
    job_title = user_info["job_title"]
    level = user_info["level"]
    language = user_info.get("language", "vi")
    job_description = user_info.get("job_description", "")
    vague_keywords = ["m∆° h·ªì", "kh√¥ng r√µ", "ch∆∞a bi·∫øt", "kh√¥ng hi·ªÉu", "unclear", "vague", "not specific", "not sure"]
    recent_feedbacks = [m["text"] for m in messages[-6:] if m["role"] == "bot"]
    vague_count = sum(any(kw in fb.lower() for kw in vague_keywords) for fb in recent_feedbacks)
    if vague_count >= 2:
        return True
    bot_questions = [m for m in messages if m["role"] == "bot" and not m["text"].startswith("üëã")]

    if len(bot_questions) >= 10:
        qa_pairs = []
        q = None
        for msg in messages:
            if msg["role"] == "bot" and not msg["text"].startswith("üëã"):
                q = msg["text"]
            elif msg["role"] == "user" and q:
                qa_pairs.append({"question": q, "answer": msg["text"]})
                q = None

        
        evaluation = evaluate_candidate_responses(job_title, messages, language)
        messages.append({
            "role": "bot",
            "text": f"{'üìù Final Evaluation:' if language == 'vi' else 'üìù Final Evaluation:'} {evaluation}"
        })

        session["finished"] = True
        session["messages"] = messages

        return True  

   
    return False


def evaluate_candidate_responses(job_title, messages, language="vi"):
    qa_pairs = []
    last_q = None
    for msg in messages:
        if msg["role"] == "bot":
            last_q = msg["text"]
        elif msg["role"] == "user" and last_q:
            qa_pairs.append({"question": last_q, "answer": msg["text"]})
            last_q = None

    answers_text = "\n\n".join([
        f"{'C√¢u h·ªèi' if language == 'vi' else 'Question'}: {qa['question']}\n{'Tr·∫£ l·ªùi' if language == 'vi' else 'Answer'}: {qa['answer']}"
        for qa in qa_pairs
    ])

    prompt_vi = f"""
    B·∫°n l√† chuy√™n gia tuy·ªÉn d·ª•ng ƒëang ƒë√°nh gi√° ·ª©ng vi√™n cho v·ªã tr√≠ {job_title}.
    D∆∞·ªõi ƒë√¢y l√† ph·∫ßn tr·∫£ l·ªùi c·ªßa ·ª©ng vi√™n:

    {answers_text}

    ƒê√°nh gi√° t·ªïng quan:
    D·ª±a v√†o c√¢u h·ªèi v√† c√¢u tr·∫£ l·ªùi c·ªßa ·ª©ng vi√™n m√† b·∫°n ƒë√°nh gi√° cho ch√≠nh x√°c c√°c y·∫øu t·ªë sau
    1. M·ª©c ƒë·ªô ph√π h·ª£p v·ªõi v·ªã tr√≠
    2. K·ªπ nƒÉng chuy√™n m√¥n th·ªÉ hi·ªán
    3. Giao ti·∫øp, logic, th√°i ƒë·ªô
    4. G·ª£i √Ω c·∫£i thi·ªán n·∫øu c√≥
    5. T·ªïng ƒëi·ªÉm /10
    L∆∞u √Ω: N·∫øu ·ª©ng vi√™n tr·∫£ l·ªùi kh√¥ng ƒë·ªß s·ªë c√¢u h·ªèi quy ƒë·ªãnh th√¨ tuy·ªát ƒë·ªëi kh√¥ng ƒë∆∞·ª£c ƒë√°nh gi√° t·ªïng ƒëi·ªÉm qua 5 ƒëi·ªÉm tr√™n thang ƒëi·ªÉm 10
    Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, ng·∫Øn g·ªçn, chuy√™n nghi·ªáp.B·∫Øt bu·ªôc sinh c√¢u tr·∫£ l·ªùi t·ªët h∆°n b·∫±ng ti·∫øng vi·ªát.Tuy·ªát ƒë·ªëi kh√¥ng c√≥ ti·∫øng anh v√†o.
    """

    prompt_en = f"""
    You are a recruiter evaluating a candidate for the position of {job_title}.
    Here are their responses:

    {answers_text}

    Please provide a concise and professional evaluation including:
    1. Suitability for the role
    2. Technical skill demonstrated
    3. Communication, logic, attitude
    4. Suggestions for improvement (if any)
    5. Overall score out of 10

    Answer in English.
    """

    prompt = prompt_vi if language == "vi" else prompt_en

    completion = client.chat.completions.create(
        model="llama3-8b-8192",
        messages=[
            {"role": "system", "content": "You are an expert recruiter."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.7
    )

    return completion.choices[0].message.content.strip()


#ph√¢n t√≠ch CV


def extract_text_from_pdf(pdf_path):
    text = ""
    reader = PdfReader(pdf_path)
    for page in reader.pages:
        text += page.extract_text() + "\n"
    return text

def extract_text_from_docx(docx_path):
    doc = Document(docx_path)
    text = ""
    for para in doc.paragraphs:
        text += para.text + "\n"
    return text

def extract_text_from_cv(cv_path):
    ext = cv_path.split(".")[-1].lower()
    if ext == "pdf":
        return extract_text_from_pdf(cv_path)
    elif ext in ["docx", "doc"]:
        return extract_text_from_docx(cv_path)
    else:
        raise ValueError("Unsupported CV file format")


from groq import Groq
import os

# Kh·ªüi t·∫°o client Groq
client = Groq(api_key=os.getenv("GROQ_API_KEY"))

def analyze_cv_and_generate_questions(cv_path, job_title, job_description, answers=None, summarize=False, language="vi"):
    if summarize and answers:
        joined_answers = "\n".join([f"Q: {a['question']}\nA: {a['answer']}" for a in answers])
        prompt = f"{job_title} - {job_description}\n{joined_answers}"

        system_prompt = "B·∫°n l√† chuy√™n gia tuy·ªÉn d·ª•ng, ƒë√°nh gi√° ·ª©ng vi√™n b·∫±ng ti·∫øng Vi·ªát." if language == "vi" else "You are a professional recruiter evaluating a candidate in English."

        try:
            response = client.chat.completions.create(
                model="llama3-8b-8192",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            print(f"Error while calling Groq API: {e}")
            return ""

    # Extract CV content
    cv_text = extract_text_from_cv(cv_path)
    context = "\n".join(retrieve_relevant_chunks(cv_text))

    # Prompt by language
    if language == "vi":
        prompt = f"""
B·∫°n l√† chuy√™n gia tuy·ªÉn d·ª•ng cho v·ªã tr√≠ {job_title}.
D∆∞·ªõi ƒë√¢y l√† ng·ªØ c·∫£nh li√™n quan t·ª´ CV v√† m√¥ t·∫£ c√¥ng vi·ªác:

--- M√î T·∫¢ C√îNG VI·ªÜC ---
{job_description}

--- NG·ªÆ C·∫¢NH T·ª™ CV ---
{context}

H√£y tr·∫£ l·ªùi 5 c√¢u h·ªèi ph·ªèng v·∫•n li√™n quan ƒë·∫øn k·ªπ nƒÉng v√† kinh nghi·ªám c·ªßa ·ª©ng vi√™n.
Ch·ªâ tr·∫£ v·ªÅ c√¢u h·ªèi m√† kh√¥ng c√≥ b·∫•t k·ª≥ ph·∫ßn gi·ªõi thi·ªáu n√†o (kh√¥ng n√≥i "Here are 5 questions" ho·∫∑c "D∆∞·ªõi ƒë√¢y l√† c√°c c√¢u h·ªèi").
"""
        system_prompt = "B·∫°n l√† chuy√™n gia tuy·ªÉn d·ª•ng, so·∫°n c√¢u h·ªèi ph·ªèng v·∫•n b·∫±ng ti·∫øng Vi·ªát."
    else:
        prompt = f"""
You are a professional recruiter for the position of {job_title}.
Here is the context from the job description and candidate's CV:

--- JOB DESCRIPTION ---
{job_description}

--- CV CONTEXT ---
{context}

Generate 5 interview questions in English, focused on the candidate's skills and experience.
Do not include any introductory statements like "Here are 5 questions" or "Below are the questions".
Only return the questions, one per line.
"""
        system_prompt = "You are a recruiter generating interview questions in English."

    try:
        # Call LLM
        response = client.chat.completions.create(
            model="llama3-8b-8192",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": prompt.strip()}
            ],
            temperature=0.5
        )

        output = response.choices[0].message.content.strip()

     
        lines = [line for line in output.split("\n") if len(line.strip()) > 5]
        questions = [q.strip("-‚Äì‚Ä¢. 1234567890").strip() for q in lines if q.strip()]  # Lo·∫°i b·ªè chu·ªói r·ªóng

        return questions
    except Exception as e:
        print(f"Error while calling Groq API: {e}")
        return []


def evaluate_single_answer(question, answer):
    logic_prompt = f"""H√£y ƒë√°nh gi√° m·ª©c ƒë·ªô ph√π h·ª£p v√† logic c·ªßa c√¢u tr·∫£ l·ªùi b√™n d∆∞·ªõi v·ªõi c√¢u h·ªèi ƒë√£ cho.
- C√¢u h·ªèi: {question}
- C√¢u tr·∫£ l·ªùi: {answer}
       

Tr·∫£ l·ªùi ng·∫Øn g·ªçn b·∫±ng ti·∫øng Vi·ªát d∆∞·ªõi 1 d√≤ng, v√≠ d·ª•: "C√¢u tr·∫£ l·ªùi t·ªët", "Kh√¥ng li√™n quan", "Thi·∫øu v√≠ d·ª•", "Logic m·ªù nh·∫°t".
"""
   

    response = client.chat.completions.create(
        model="llama3-8b-8192",
        messages=[
            {"role": "system", "content": "B·∫°n l√† chuy√™n gia ƒë√°nh gi√° ƒë·ªô ph√π h·ª£p gi·ªØa c√¢u h·ªèi v√† c√¢u tr·∫£ l·ªùi."},
            {"role": "user", "content": logic_prompt.strip()}
        ],
        temperature=0
    )

    return response.choices[0].message.content.strip()

def evaluate_candidate_responses_voice(job_title, answers, language="vi"):
    answers_text = "\n\n".join([
        f"C√¢u h·ªèi: {qa['question']}\nTr·∫£ l·ªùi: {qa['answer']}" if language == "vi"
        else f"Question: {qa['question']}\nAnswer: {qa['answer']}"
        for qa in answers
    ])
    def evaluate_technical_score(answers):
        score = 0
        for answer in answers:
            if "kh√¥ng bi·∫øt" in answer["answer"] or "ch∆∞a t·ª´ng c√≥ kinh nghi·ªám" in answer["answer"]:
                score += 10 
            elif "kh√¥ng c√≥ c√¢u tr·∫£ l·ªùi" in answer["answer"]:
                score += 5 
            else:
                score += 30  
        return score // len(answers) if len(answers) > 0 else 0

    def evaluate_communication_score(answers):
        score = 0
        for answer in answers:
            if "kh√¥ng bi·∫øt" in answer["answer"] or "kh√¥ng c√≥ c√¢u tr·∫£ l·ªùi" in answer["answer"]:
                score += 20  
            elif len(answer["answer"]) < 50: 
                score += 50
            else:
                score += 80  
        return score // len(answers) if len(answers) > 0 else 0

    def evaluate_fit_score(answers):
        score = 0
        for answer in answers:
            if "kh√¥ng bi·∫øt" in answer["answer"] or "kh√¥ng c√≥ c√¢u tr·∫£ l·ªùi" in answer["answer"]:
                score += 20 
            else:
                score += 60  
        return score // len(answers) if len(answers) > 0 else 0

    technical_score = evaluate_technical_score(answers)
    communication_score = evaluate_communication_score(answers)
    fit_score = evaluate_fit_score(answers)

    total_score = (technical_score + communication_score + fit_score) // 3


    if language == "vi":
       
        prompt_text = f"""
        B·∫°n l√† m·ªôt chuy√™n gia tuy·ªÉn d·ª•ng ƒëang ƒë√°nh gi√° ·ª©ng vi√™n cho v·ªã tr√≠ {job_title}.

        D∆∞·ªõi ƒë√¢y l√† c√¢u tr·∫£ l·ªùi c·ªßa ·ª©ng vi√™n:

        {answers_text}

        H√£y ƒë∆∞a ra **ƒë√°nh gi√° t·ªïng quan** v·ªÅ ·ª©ng vi√™n d·ª±a tr√™n c√°c c√¢u tr·∫£ l·ªùi c·ªßa h·ªç, bao g·ªìm c√°c m·ª•c sau:

        1. **∆Øu ƒëi·ªÉm**: Ch·ªâ r√µ nh·ªØng ƒëi·ªÉm m·∫°nh n·ªïi b·∫≠t c·ªßa ·ª©ng vi√™n t·ª´ c√°c c√¢u tr·∫£ l·ªùi.
        2. **Nh∆∞·ª£c ƒëi·ªÉm (n·∫øu c√≥)**: Nh·ªØng thi·∫øu s√≥t ho·∫∑c c√°c k·ªπ nƒÉng c·∫ßn c·∫£i thi·ªán m√† b·∫°n nh·∫≠n th·∫•y t·ª´ c√°c c√¢u tr·∫£ l·ªùi c·ªßa ·ª©ng vi√™n.
        3. **Gi·ªçng n√≥i & m·ª©c ƒë·ªô t·ª± tin**: ƒê√°nh gi√° ng·ªØ ƒëi·ªáu, s·ª± r√µ r√†ng v√† t·ª± tin trong c√°ch th·ªÉ hi·ªán c√¢u tr·∫£ l·ªùi c·ªßa ·ª©ng vi√™n.
        4. **G·ª£i √Ω c·∫£i thi·ªán**: ƒê∆∞a ra nh·ªØng l·ªùi khuy√™n c·ª• th·ªÉ gi√∫p ·ª©ng vi√™n c·∫£i thi·ªán k·ªπ nƒÉng, c√°ch tr·∫£ l·ªùi v√† th·ªÉ hi·ªán s·ª± t·ª± tin h∆°n.

        **ƒê·ªìng th·ªùi, ch·∫•m ƒëi·ªÉm ·ª©ng vi√™n theo c√°c ti√™u ch√≠ sau (theo thang ƒëi·ªÉm 0‚Äì100%):**

        - **Technical Score**: ƒê√°nh gi√° m·ª©c ƒë·ªô hi·ªÉu bi·∫øt chuy√™n m√¥n v√† k·ªπ nƒÉng li√™n quan ƒë·∫øn c√¥ng vi·ªác, tr√™n c∆° s·ªü c√°c c√¢u tr·∫£ l·ªùi c·ªßa ·ª©ng vi√™n.
        - **Communication Score**: ƒê√°nh gi√° kh·∫£ nƒÉng giao ti·∫øp, c√°ch di·ªÖn ƒë·∫°t v√† s·ª± t∆∞∆°ng t√°c c·ªßa ·ª©ng vi√™n trong c√°c c√¢u tr·∫£ l·ªùi.
        - **Fit Score**: M·ª©c ƒë·ªô ph√π h·ª£p c·ªßa ·ª©ng vi√™n v·ªõi v·ªã tr√≠ ·ª©ng tuy·ªÉn v√† vƒÉn h√≥a c√¥ng ty, d·ª±a tr√™n c√¢u tr·∫£ l·ªùi c·ªßa h·ªç.

        Cu·ªëi c√πng, ƒë∆∞a ra **t·ªïng ƒëi·ªÉm** theo thang ƒëi·ªÉm 5, ph·∫£n √°nh t·ªïng th·ªÉ nƒÉng l·ª±c v√† s·ª± ph√π h·ª£p c·ªßa ·ª©ng vi√™n v·ªõi c√¥ng vi·ªác.

        Y√™u c·∫ßu: Tr·∫£ l·ªùi ng·∫Øn g·ªçn, r√µ r√†ng, s·ª≠ d·ª•ng ng√¥n ng·ªØ chuy√™n nghi·ªáp v√† b·∫±ng **ti·∫øng Vi·ªát**.
        - **∆Øu ƒëi·ªÉm:** (tr·∫£ l·ªùi)
        - **Nh∆∞·ª£c ƒëi·ªÉm:** (tr·∫£ l·ªùi)
        - **Gi·ªçng n√≥i & m·ª©c ƒë·ªô t·ª± tin:** (tr·∫£ l·ªùi)
        - **G·ª£i √Ω c·∫£i thi·ªán:** (tr·∫£ l·ªùi)
        - **Technical Score:** {technical_score}%
        - **Communication Score:** {communication_score}%
        - **Fit Score:** {fit_score}%
        - **T·ªïng ƒëi·ªÉm:** {total_score}/100
        """

        name = session.get("name", "·ª®ng vi√™n ch∆∞a cung c·∫•p t√™n")
        # Prompt cho ph√°t √¢m thanh
        prompt_audio = f"""
        B·∫°n l√† chuy√™n gia tuy·ªÉn d·ª•ng. H√£y ƒë√°nh gi√° ·ª©ng vi√™n cho v·ªã tr√≠ {job_title} b·∫±ng gi·ªçng ƒëi·ªáu t·ª± nhi√™n, nh∆∞ th·ªÉ b·∫°n ƒëang tr√≤ chuy·ªán tr·ª±c ti·∫øp v·ªõi ·ª©ng vi√™n.

        X∆∞ng h√¥ b·∫Øt bu·ªôc:
        - X∆∞ng "t√¥i" v√† g·ªçi ·ª©ng vi√™n l√† "b·∫°n" xuy√™n su·ªët to√†n b·ªô ph·∫ßn n√≥i.
        - Tuy·ªát ƒë·ªëi kh√¥ng s·ª≠ d·ª•ng c√°c c√°ch x∆∞ng h√¥ kh√°c nh∆∞: "em", "anh", "ch·ªã", "·ª©ng vi√™n", v.v.
        - Kh√¥ng d√πng c√°c t·ª´ mang t√≠nh l·ªÖ nghi m√°y m√≥c nh∆∞ "th∆∞a", "k√≠nh g·ª≠i", "d·∫°".

        Gi·ªçng vƒÉn:
        - S·ª≠ d·ª•ng ng√¥n ng·ªØ n√≥i h√†ng ng√†y nh∆∞ng l·ªãch s·ª± v√† chuy√™n nghi·ªáp.
        - H·∫°n ch·∫ø t·ªëi ƒëa c√°c c√¢u s√°o r·ªóng, m√°y m√≥c, h√£y tr√¨nh b√†y t·ª± nhi√™n v√† ch√¢n th·∫≠t.
        - N·∫øu c√≥ n√≥i ti·∫øng anh c√°c t·ª´ chuy√™n ng√†nh b·∫°n ph·∫£i ƒë·ªçc ti·∫øng anh cho chu·∫©n. Ng·ªØ ƒëi·ªáu chu·∫©n.

        N·ªôi dung ƒë√°nh gi√° c·∫ßn tr√¨nh b√†y theo c√°c ph·∫ßn sau:
        1. Nh·∫≠n x√©t v·ªÅ **∆∞u ƒëi·ªÉm n·ªïi b·∫≠t** c·ªßa b·∫°n, v√≠ d·ª•: ‚ÄúT√¥i th·∫•y b·∫°n c√≥ ∆∞u ƒëi·ªÉm l√†...‚Äù
        2. Nh·∫≠n x√©t v·ªÅ **ƒëi·ªÉm c·∫ßn c·∫£i thi·ªán**, v√≠ d·ª•: ‚ÄúTuy nhi√™n, b·∫°n c·∫ßn c·∫£i thi·ªán ·ªü ph·∫ßn...‚Äù
        3. Nh·∫≠n x√©t v·ªÅ **gi·ªçng n√≥i**, **ng·ªØ ƒëi·ªáu** v√† **m·ª©c ƒë·ªô t·ª± tin** khi tr·∫£ l·ªùi
        4. ƒê∆∞a ra **l·ªùi khuy√™n c·ª• th·ªÉ**, kh√≠ch l·ªá ph√°t tri·ªÉn
        5. K·∫øt lu·∫≠n b·∫±ng **t·ªïng ƒëi·ªÉm ƒë√°nh gi√° tr√™n thang ƒëi·ªÉm 5**, k√®m theo l√Ω do

        üõë L∆∞u √Ω:
        - ·ª®ng vi√™n ƒë√£ ch·ªçn ti·∫øng Vi·ªát, v√¨ v·∫≠y **kh√¥ng ƒë∆∞·ª£c s·ª≠ d·ª•ng ti·∫øng Anh** d∆∞·ªõi b·∫•t k·ª≥ h√¨nh th·ª©c n√†o.
        - T·∫•t c·∫£ ph·∫£n h·ªìi ph·∫£i ƒë∆∞·ª£c tr√¨nh b√†y r√µ r√†ng, d·ªÖ hi·ªÉu v√† ph√π h·ª£p v·ªõi m·ªôt chuy√™n gia nh√¢n s·ª± c√≥ kinh nghi·ªám.

        D∆∞·ªõi ƒë√¢y l√† c√°c c√¢u tr·∫£ l·ªùi c·ªßa ·ª©ng vi√™n:
        {answers_text}

        H√£y tr√¨nh b√†y ph·∫ßn ƒë√°nh gi√° c·ªßa b·∫°n b·∫±ng ti·∫øng Vi·ªát, ƒë√∫ng gi·ªçng ƒëi·ªáu nh∆∞ y√™u c·∫ßu tr√™n.
        """

    else:
        # Prompt for display
         prompt_text = f"""
        You are an HR expert evaluating a candidate for the position of {job_title}.

        Below are the candidate's responses:

        {answers_text}

        Please provide an overall evaluation including:

        1. Candidate's strengths
        2. Weaknesses (if any)
        3. Voice clarity and confidence
        4. Suggestions for improvement
        5. Final score out of 100

        Respond in English, be concise and professional.

        Scores:
        - **Technical Score**: {technical_score}%
        - **Communication Score**: {communication_score}%
        - **Fit Score**: {fit_score}%
        - **Total Score**: {total_score}/100
        """

       
         prompt_audio = f"""
        You are an HR expert. Please evaluate the candidate for the {job_title} position in a natural conversational tone.
        Do not list items with numbers. Speak smoothly as if you're giving live feedback to the candidate.
        Example: "I think you showed strength in..., but you need to improve..., and with some more practice, you'll stand out."
        Conclude with an overall score out of 5. Respond in fluent English.
        Below are the candidate's responses:
        {answers_text}
        """
    response_text = client.chat.completions.create(
        model="llama3-8b-8192",
        messages=[
            {"role": "system", "content": "B·∫°n l√† chuy√™n gia tuy·ªÉn d·ª•ng, vi·∫øt b·∫£n ƒë√°nh gi√° b·∫±ng ti·∫øng Vi·ªát." if language == "vi" else "You are an HR expert evaluating candidates."},
            {"role": "user", "content": prompt_text.strip()}
        ]
    )
    response_audio = client.chat.completions.create(
        model="llama3-8b-8192",
        messages=[
            {"role": "system", "content": "B·∫°n l√† chuy√™n gia tuy·ªÉn d·ª•ng, n√≥i chuy·ªán ƒë√°nh gi√° b·∫±ng gi·ªçng t·ª± nhi√™n ti·∫øng Vi·ªát v·ªõi t·ªëc ƒë·ªô nhanh." if language == "vi" else "You are an HR expert giving spoken feedback naturally in English."},
            {"role": "user", "content": prompt_audio}  
        ]
    )
    return {
        "text": response_text.choices[0].message.content.strip(), 
        "audio": response_audio.choices[0].message.content  
    }


def ask_question_cv(cv_text, job_title, job_description, language="vi"):
    """
    Sinh M·ªòT c√¢u h·ªèi ph·ªèng v·∫•n d·ª±a v√†o n·ªôi dung CV v√† m√¥ t·∫£ c√¥ng vi·ªác b·∫±ng Langchain v√† Groq.

    Args:
        cv_text (str): N·ªôi dung CV ·ª©ng vi√™n (PDF ho·∫∑c DOCX ƒë√£ tr√≠ch xu·∫•t)
        job_title (str): V·ªã tr√≠ ·ª©ng tuy·ªÉn
        job_description (str): M√¥ t·∫£ c√¥ng vi·ªác
        language (str): 'vi' ho·∫∑c 'en'

    Returns:
        str: C√¢u h·ªèi ph·ªèng v·∫•n
    """
    context = "\n".join(retrieve_relevant_chunks(cv_text)) 
    if not context:
        print("L·ªói: Kh√¥ng c√≥ ng·ªØ c·∫£nh t·ª´ CV ƒë∆∞·ª£c tr√≠ch xu·∫•t!")
        return []
    if language == "vi":
        prompt = f"""
B·∫°n l√† chuy√™n gia nh√¢n s·ª± ƒëang tuy·ªÉn v·ªã tr√≠: {job_title}.

--- M√î T·∫¢ C√îNG VI·ªÜC ---
{job_description}

--- N·ªòI DUNG CV ·ª®NG VI√äN ---
{context}

üëâ Vi·∫øt ra ƒë√∫ng M·ªòT c√¢u h·ªèi ph·ªèng v·∫•n b·∫±ng ti·∫øng Vi·ªát, ng·∫Øn g·ªçn, r√µ r√†ng, s√°t v·ªõi y√™u c·∫ßu c√¥ng vi·ªác v√† n·ªôi dung CV.
KH√îNG ch√†o h·ªèi, KH√îNG li·ªát k√™, KH√îNG ƒë√°nh s·ªë. Ch·ªâ tr·∫£ v·ªÅ n·ªôi dung c√¢u h·ªèi duy nh·∫•t ƒë·ªÉ c√≥ th·ªÉ ƒë·ªçc to b·∫±ng gi·ªçng n√≥i.D√πng ti·∫øng vi·ªát ngay c√¢u ƒë·∫ßu ti√™n kh√¥ng ƒë∆∞·ª£c d√πng ti·∫øng anh.
""".strip()
    else:
        prompt = f"""
You are a recruiter hiring for the role: {job_title}.

--- JOB DESCRIPTION ---
{job_description}

--- CANDIDATE CV CONTENT ---
{context}

üëâ Write exactly ONE interview question in English based on the job requirements and candidate profile.
DO NOT include any greetings, lists, or explanations. Only return the interview question itself, concise and suitable for voice-based delivery.
""".strip()
    llm = langchain_ollama(model="llama3-8b-8192") 
    embeddings = OllamaEmbeddings(model="llama3-8b-8192")   
    vectorstore = FILE_ATTRIBUTE_COMPRESSED.from_texts([context], embeddings)
    qa_chain = RetrievalQA.from_chain_type(llm=llm, chain_type="stuff", vectorstore=vectorstore)
    response = qa_chain.run(prompt)

    return response.strip()




# ƒê·ªçc d·ªØ li·ªáu t·ª´ JSON
def load_data(json_file_path):
    with open(json_file_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    return data

# H√†m chia vƒÉn b·∫£n th√†nh c√°c chunks nh·ªè
def split_into_chunks(text, chunk_size=20):
    words = text.split()
    chunks = [' '.join(words[i:i + chunk_size]) for i in range(0, len(words), chunk_size)]
    return chunks

# Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu
def preprocess_data(data):
    for item in data:
        item["chunks"] = split_into_chunks(item["objective"])  # Chia m·ª•c ti√™u ngh·ªÅ nghi·ªáp th√†nh chunks
    return data

def preprocess_data_experience(data):
    for item in data:
        item["chunks"] = split_into_chunks(item["job_desc"])  # ‚Üê ƒë√∫ng key cho experience
    return data

# T·∫°o FAISS Index
def create_faiss_index(chunks):
    embeddings = np.array([np.random.random(128).astype('float32') for _ in chunks]) 
    index = faiss.IndexFlatL2(128)
    index.add(embeddings)
    return index

# T√¨m ki·∫øm chunk li√™n quan trong FAISS
def search_relevant_chunks(query, index, all_chunks):
    query_embedding = np.random.random(128).astype('float32')  
    k = 3  
    D, I = index.search(np.array([query_embedding]), k)
    relevant_chunks = [all_chunks[i] for i in I[0]]
    return relevant_chunks

def generate_response_with_groq(query, relevant_chunks):
    try:
       
        detected_language = detect(query)
    except:
        detected_language = "vi"  
    if detected_language == "vi":  
        prompt_text = f"""
        B·∫°n l√† m·ªôt chuy√™n gia t∆∞ v·∫•n ngh·ªÅ nghi·ªáp. B·∫°n s·∫Ω c·∫£i thi·ªán m·ª•c ti√™u ngh·ªÅ nghi·ªáp c·ªßa ng∆∞·ªùi d√πng d·ª±a tr√™n th√¥ng tin t√¥i cung c·∫•p d∆∞·ªõi ƒë√¢y.Tuy·ªát ƒë·ªëi kh√¥ng c√≥ ti·∫øng anh v√†o. 

        1. **V·ªã tr√≠ c√¥ng vi·ªác**: L·∫≠p tr√¨nh vi√™n ph·∫ßn m·ªÅm
        2. **M·ª•c ti√™u ngh·ªÅ nghi·ªáp ban ƒë·∫ßu**: {query}
        3. **Th√¥ng tin b·ªï sung li√™n quan**: 
        - {', '.join(relevant_chunks)}

        H√£y gi√∫p t√¥i l√†m r√µ v√† ph√°t tri·ªÉn m·ª•c ti√™u ngh·ªÅ nghi·ªáp c·ªßa ng∆∞·ªùi d√πng theo ba c·∫•p ƒë·ªô:
        1. **Condensed**: Vi·∫øt ng·∫Øn g·ªçn, s√∫c t√≠ch nh∆∞ng v·∫´n ƒë·ªß th√¥ng tin.
        2. **Extended**: Vi·∫øt chi ti·∫øt h∆°n, l√†m r√µ c√°c m·ª•c ti√™u ngh·ªÅ nghi·ªáp, k·ªπ nƒÉng v√† kinh nghi·ªám.
        3. **Suggestions**: ƒê∆∞a ra m·ªôt s·ªë g·ª£i √Ω c·∫£i thi·ªán m·ª•c ti√™u ngh·ªÅ nghi·ªáp.
        """
    else: 
        prompt_text = f"""
        You are a career consultant. You will help refine and develop the user's career goals based on the information I provide below.

        1. **Job Title**: Software Developer
        2. **Initial Career Goal**: {query}
        3. **Additional Related Information**:
        - {', '.join(relevant_chunks)}

        Please help me clarify and develop the user's career goals at three levels:
        1. **Condensed**: Write concisely, but still provide the essential information.
        2. **Extended**: Write in more detail, clarifying career goals, skills, and experience.
        3. **Suggestions**: Give some suggestions to improve the career goals.
        """

    response_text = client.chat.completions.create(
        model="llama3-8b-8192",
        messages=[
            {"role": "system", "content": "You are a career consultant helping to improve the user's career goals."},
            {"role": "user", "content": prompt_text.strip()}
        ]
    )
    try:
        if response_text and hasattr(response_text, 'choices') and len(response_text.choices) > 0:
            message_content = response_text.choices[0].message.content  
        else:
            return "Unable to generate career goals. Please try again later."
    except Exception as e:
        print(f"Error extracting response content: {str(e)}")
        return "An error occurred while processing the request. Please try again."

    return message_content  

def generate_response_experience(job_desc, relevant_chunks):
    try:
        detected_language = detect(job_desc)
    except:
        detected_language = "vi"

    if detected_language == "vi":
        prompt_text = f"""
        B·∫°n l√† m·ªôt chuy√™n gia vi·∫øt CV. H√£y c·∫£i thi·ªán ph·∫ßn m√¥ t·∫£ kinh nghi·ªám l√†m vi·ªác d·ª±a tr√™n ph·∫ßn m√¥ t·∫£ sau v√† m·ªôt s·ªë m·∫´u g·ª£i √Ω d∆∞·ªõi ƒë√¢y. Kh√¥ng ƒë∆∞·ª£c d√πng ti·∫øng Anh.

        1. **M√¥ t·∫£ g·ªëc c·ªßa ng∆∞·ªùi d√πng**: {job_desc}
        2. **D·ªØ li·ªáu g·ª£i √Ω t·ª´ h·ªá th·ªëng**: {', '.join(relevant_chunks)}

        Vi·∫øt l·∫°i ph·∫ßn m√¥ t·∫£ kinh nghi·ªám d∆∞·ªõi d·∫°ng c√°c g·∫°ch ƒë·∫ßu d√≤ng, ch√∫ √Ω nh·∫•n m·∫°nh c√°c k·ªπ nƒÉng v√† k·∫øt qu·∫£:
        - K·ªπ nƒÉng ch√≠nh
        - C√¥ng vi·ªác v√† tr√°ch nhi·ªám
        - Th√†nh t·ª±u ƒë·∫°t ƒë∆∞·ª£c
        - C√°c k·ªπ nƒÉng b·ªï sung kh√°c
        """
    else:
        prompt_text = f"""
        You are a CV writing assistant. Improve the user's job experience description based on the draft and related examples below.

        1. **User's original description**: {job_desc}
        2. **System reference examples**: {', '.join(relevant_chunks)}

        Rewrite the job experience in bullet points, focusing on skills, responsibilities, achievements, and additional skills:
        - Key skills
        - Responsibilities and duties
        - Achievements and impact
        - Additional relevant skills
        """

    response_text = client.chat.completions.create(
        model="llama3-8b-8192",
        messages=[
            {"role": "system", "content": "You are a resume writing assistant improving job experience content."},
            {"role": "user", "content": prompt_text.strip()}
        ]
    )

    try:
        if response_text and hasattr(response_text, 'choices') and len(response_text.choices) > 0:
            return response_text.choices[0].message.content
        else:
            return "Kh√¥ng th·ªÉ t·∫°o m√¥ t·∫£ kinh nghi·ªám, vui l√≤ng th·ª≠ l·∫°i sau."
    except Exception as e:
        print(f"L·ªói t·∫°o n·ªôi dung: {str(e)}")
        return "ƒê√£ x·∫£y ra l·ªói khi x·ª≠ l√Ω d·ªØ li·ªáu."



def perform_rag_task(json_file_path, query):
    data = load_data(json_file_path)
    preprocessed_data = preprocess_data(data)
    all_chunks = [item['chunks'] for item in preprocessed_data]
    index = create_faiss_index([chunk for chunks in all_chunks for chunk in chunks])
    relevant_chunks = search_relevant_chunks(query, index, [chunk for chunks in all_chunks for chunk in chunks])
    response = generate_response_with_groq(query, relevant_chunks)
    return response

def perform_rag_experience_task(json_file_path, query):
    data = load_data(json_file_path)
    preprocessed_data = preprocess_data_experience(data)
    all_chunks = [item['chunks'] for item in preprocessed_data]
    flat_chunks = [chunk for chunks in all_chunks for chunk in chunks]
    index = create_faiss_index(flat_chunks)
    relevant_chunks = search_relevant_chunks(query, index, flat_chunks)

    # G·ªçi prompt chuy√™n g·ª£i √Ω kinh nghi·ªám l√†m vi·ªác
    response = generate_response_experience(query, relevant_chunks)
    return response


